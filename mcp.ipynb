{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:07.452550Z",
     "start_time": "2025-05-19T18:51:07.447796Z"
    }
   },
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tool function",
   "id": "83f89b1b4e7cb381"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:08.721434Z",
     "start_time": "2025-05-19T18:51:08.714684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAPER_DIR = \"papers\"\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "    # Use arxiv to find the papers\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids"
   ],
   "id": "989e44c557bcac10",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:11.222301Z",
     "start_time": "2025-05-19T18:51:09.613553Z"
    }
   },
   "cell_type": "code",
   "source": "search_papers(\"computers\")",
   "id": "fef44aedf228c44d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:11.998700Z",
     "start_time": "2025-05-19T18:51:11.994230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "\n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "\n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ],
   "id": "d5c3d7f4a412068c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:13.146628Z",
     "start_time": "2025-05-19T18:51:13.142939Z"
    }
   },
   "cell_type": "code",
   "source": "extract_info('1310.7911v2')",
   "id": "bbea2866f521dcc0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tool mapping",
   "id": "c00e771c06ea5319"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:18.900122Z",
     "start_time": "2025-05-19T18:51:18.895474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_papers\",\n",
    "            \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The topic to search for\"\n",
    "                    },\n",
    "                    \"max_results\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum number of results to retrieve\",\n",
    "                        \"default\": 5\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_info\",\n",
    "            \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"paper_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ID of the paper to look for\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"paper_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ],
   "id": "68e2f71b9f2bd51a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:20.120030Z",
     "start_time": "2025-05-19T18:51:20.117384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Map tool names to their functions\n",
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \"\"\"Execute a tool function and format the result as a string.\"\"\"\n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ],
   "id": "e379802a9b7e04f1",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chatbot codem",
   "id": "721e461ba5cdf149"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:21.663441Z",
     "start_time": "2025-05-19T18:51:21.631335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "client = openai.OpenAI()"
   ],
   "id": "b24fd785e72d7cb4",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:22.462045Z",
     "start_time": "2025-05-19T18:51:22.456582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_query(query):\n",
    "    \"\"\"Process a user query, handling any tool calls that may be required.\"\"\"\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "\n",
    "    while True:\n",
    "        # Make the API call to OpenAI\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            max_tokens=2024\n",
    "        )\n",
    "\n",
    "        # Get the assistant's message from the response\n",
    "        assistant_message = response.choices[0].message\n",
    "\n",
    "        # Add the assistant's message to our conversation history\n",
    "        messages.append({\n",
    "            'role': 'assistant',\n",
    "            'content': assistant_message.content,\n",
    "            'tool_calls': assistant_message.tool_calls if hasattr(assistant_message, 'tool_calls') else None\n",
    "        })\n",
    "\n",
    "        # Print the assistant's text response if any\n",
    "        if assistant_message.content:\n",
    "            print(assistant_message.content)\n",
    "\n",
    "        # Check if there are any tool calls to process\n",
    "        if not hasattr(assistant_message, 'tool_calls') or not assistant_message.tool_calls:\n",
    "            # No tool calls, we're done\n",
    "            break\n",
    "\n",
    "        # Process each tool call\n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            tool_id = tool_call.id\n",
    "            function_name = tool_call.function.name\n",
    "\n",
    "            # Parse the arguments from JSON string to Python dict\n",
    "            try:\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "            except json.JSONDecodeError:\n",
    "                function_args = {}\n",
    "\n",
    "            print(f\"Calling tool {function_name} with args {function_args}\")\n",
    "\n",
    "            # Execute the tool and get the result\n",
    "            result = execute_tool(function_name, function_args)\n",
    "\n",
    "            # Add the tool result to the conversation\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_id,\n",
    "                \"content\": result\n",
    "            })\n",
    "\n",
    "    return messages"
   ],
   "id": "8d76afb81acf0ffe",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:51:26.502661Z",
     "start_time": "2025-05-19T18:51:26.499397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "\n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ],
   "id": "87a4a7f7d9322b5f",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T18:52:03.032027Z",
     "start_time": "2025-05-19T18:51:27.582764Z"
    }
   },
   "cell_type": "code",
   "source": "chat_loop()",
   "id": "65ef89db16b99eea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Calling tool search_papers with args {'topic': 'graph neural network', 'max_results': 5}\n",
      "Results are saved in: papers/graph_neural_network/papers_info.json\n",
      "Calling tool extract_info with args {'paper_id': '2307.00865v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2007.06559v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2011.01412v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2412.01176v1'}\n",
      "Calling tool extract_info with args {'paper_id': '1908.00187v1'}\n",
      "Here are some recent papers related to Graph Neural Networks:\n",
      "\n",
      "1. **A Survey on Graph Classification and Link Prediction based on GNN**\n",
      "   - **Authors:** Xingyu Liu, Juan Chen, Quan Wen\n",
      "   - **Published:** July 3, 2023\n",
      "   - **Summary:** This comprehensive review article discusses graph convolutional neural networks (GCNs), focusing on their application in various tasks such as node classification, graph classification, and link prediction. It elaborates on fundamental concepts, attention mechanisms, and autoencoders along with associated datasets.\n",
      "   - [Read the full paper here](http://arxiv.org/pdf/2307.00865v1)\n",
      "\n",
      "2. **Graph Structure of Neural Networks**\n",
      "   - **Authors:** Jiaxuan You, Jure Leskovec, Kaiming He, Saining Xie\n",
      "   - **Published:** July 13, 2020\n",
      "   - **Summary:** This paper investigates how the graph structure of neural networks impacts their predictive performance. The authors introduce a relational graph representation for neural networks, revealing correlations between network structure and performance, and suggesting a 'sweet spot' for graph structures that optimize predictive capabilities.\n",
      "   - [Read the full paper here](http://arxiv.org/pdf/2007.06559v2)\n",
      "\n",
      "3. **Sampling and Recovery of Graph Signals based on Graph Neural Networks**\n",
      "   - **Authors:** Siheng Chen, Maosen Li, Ya Zhang\n",
      "   - **Published:** November 3, 2020\n",
      "   - **Summary:** This paper proposes interpretable graph neural networks for sampling and recovering graph signals. It introduces a graph neural sampling module for selecting informative vertices, allowing for reconstruction of original graph signals and achieving significant improvements in classification accuracy in several tasks.\n",
      "   - [Read the full paper here](http://arxiv.org/pdf/2011.01412v1)\n",
      "\n",
      "4. **Superhypergraph Neural Networks and Plithogenic Graph Neural Networks: Theoretical Foundations**\n",
      "   - **Authors:** Takaaki Fujita\n",
      "   - **Published:** December 2, 2024\n",
      "   - **Summary:** This paper establishes the theoretical foundations for SuperHyperGraph Neural Networks and Plithogenic Graph Neural Networks, generalizing traditional graph structures to model complex relationships while discussing the potential applications of these frameworks in neural networks.\n",
      "   - [Read the full paper here](http://arxiv.org/pdf/2412.01176v1)\n",
      "\n",
      "5. **Graph Neural Networks for Small Graph and Giant Network Representation Learning: An Overview**\n",
      "   - **Authors:** Jiawei Zhang\n",
      "   - **Published:** August 1, 2019\n",
      "   - **Summary:** This overview introduces various types of graph neural network models designed for representation learning on different types of graph data, specifically small graphs and giant networks, providing insights into the architectures and their applications.\n",
      "   - [Read the full paper here](http://arxiv.org/pdf/1908.00187v1)\n",
      "\n",
      "Feel free to ask if you need more information on this topic!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%writefile mcp_project/research_server.py\n",
    "\n",
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "\n",
    "PAPER_DIR = \"papers\"\n",
    "\n",
    "# Initialize FastMCP server\n",
    "mcp = FastMCP(\"research\")\n",
    "\n",
    "@mcp.tool()\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "    # Use arxiv to find the papers\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids\n",
    "\n",
    "@mcp.tool()\n",
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "\n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "\n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize and run the server\n",
    "    mcp.run(transport='stdio')"
   ],
   "id": "37839b8f533bf985"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
